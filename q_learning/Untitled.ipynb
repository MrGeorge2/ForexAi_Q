{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, CuDNNLSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import time as t_lib\n",
    "import tensorflow as tf\n",
    "from threading import Thread\n",
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFRAME_NAME = 'EURUSD_m15_Ask_ready.csv'\n",
    "NUMBER_OF_SAMPLES = 50\n",
    "\n",
    "EPISODES = 5000\n",
    "TICQTY_MAX = 55000\n",
    "HOLD_REWARD = -1\n",
    "OPEN_TRADE_REWARD = 0\n",
    "CLOSING_TRADE_WITH_OPENING = 5\n",
    "DIVIDE_PRICE_UNDER_LOCAL_MINIMA = 10\n",
    "REWARD_FOR_PIPS = 10000\n",
    "TIMES_FACTOR = 1\n",
    "\n",
    "ACTION_DECODE = {\n",
    "    0: 0,\n",
    "    1: 0.5,\n",
    "    2: 1,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "class Dataframe:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._dataframe = self._load()[:2000]\n",
    "        self.__scaler = MinMaxScaler()\n",
    "\n",
    "    @property\n",
    "    def lenght(self):\n",
    "        return len(self._dataframe.index) - NUMBER_OF_SAMPLES\n",
    "\n",
    "    def get(self, sample_number):\n",
    "        if sample_number > self.lenght or sample_number < 0:\n",
    "            raise ValueError(\"Sample number out of range (0 - {self.lenght})\")\n",
    "\n",
    "        start_index = sample_number\n",
    "        end_index = start_index + NUMBER_OF_SAMPLES\n",
    "\n",
    "        df_sample = self._dataframe[start_index: end_index]\n",
    "\n",
    "        last_open = df_sample.at[df_sample.index[-1], 'open']\n",
    "        last_close = df_sample.at[df_sample.index[-1], 'close']\n",
    "\n",
    "        df_sample = df_sample[['open', 'close', 'high', 'low', 'tickqty', 'hours', 'minutes']].values\n",
    "        df_sample = self._scale(df_sample, start=0, end=4)\n",
    "        return np.expand_dims(df_sample, axis=0), last_open, last_close\n",
    "\n",
    "    @staticmethod\n",
    "    def _load():\n",
    "        \"\"\" Creating relative path and then loading the df_path \"\"\"\n",
    "        \"\"\"\n",
    "        df_path = os.path.join(os.path.dirname(os.path.abspath(__file__)) +\n",
    "                               os.path.normpath(f'/dfs/{cfg.DATAFRAME_NAME}'))\n",
    "        \"\"\"\n",
    "        df_path = './dfs/{}'.format(DATAFRAME_NAME)\n",
    "        df = pd.read_csv(\n",
    "            df_path,\n",
    "            dtype={\n",
    "                'datetime'\n",
    "                'open': np.float32,\n",
    "                'close': np.float32,\n",
    "                'high': np.float32,\n",
    "                'low': np.float32,\n",
    "                'tickqty': np.float32,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # df['hours']= pd.to_datetime(df['datetime'], format='%Y%m%d %H:%M:%S.%f').dt.hour / 24\n",
    "        df['hours'] = pd.to_datetime(df['date'], format='%m-%d-%Y %H:%M:%S').dt.hour / 24\n",
    "        df['minutes'] = pd.to_datetime(df['date'], format='%m-%d-%Y %H:%M:%S').dt.minute / 64\n",
    "        df['tickqty'] = df['tickqty'] / TICQTY_MAX\n",
    "        return df\n",
    "\n",
    "    def _scale(self, array: np.ndarray, start: int, end: int):\n",
    "        columns = array.T[start: end].T\n",
    "\n",
    "        self.__scaler.fit(columns)\n",
    "        scaled_cols = self.__scaler.transform(columns).T\n",
    "        array.T[start:end] = scaled_cols\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size, batch_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=20000)\n",
    "        self.sample_memory = deque()\n",
    "        \n",
    "        self.gamma = 0.99  # discount rate\n",
    "        \n",
    "        self.epsilon = 1 # exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.9999\n",
    "        \n",
    "        self.learning_rate = 0.1\n",
    "        self.learning_rate_decay = 0.999\n",
    "        self.learning_rate_min = 0.002\n",
    "        \n",
    "        self.batch_size_samples = 1000\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.update_target_model()\n",
    "\n",
    "    \"\"\"Huber loss for Q Learning\n",
    "\n",
    "    References: https://en.wikipedia.org/wiki/Huber_loss\n",
    "                https://www.tensorflow.org/api_docs/python/tf/losses/huber_loss\n",
    "    \"\"\"\n",
    "\n",
    "    def _huber_loss(self, y_true, y_pred, clip_delta=1.0):\n",
    "        error = y_true - y_pred\n",
    "        cond = K.abs(error) <= clip_delta\n",
    "\n",
    "        squared_loss = 0.5 * K.square(error)\n",
    "        quadratic_loss = 0.5 * K.square(clip_delta) + clip_delta * (K.abs(error) - clip_delta)\n",
    "\n",
    "        return K.mean(tf.where(cond, squared_loss, quadratic_loss))\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(CuDNNLSTM(units=50, return_sequences=True, input_shape=self.state_size))\n",
    "\n",
    "        model.add(CuDNNLSTM(units=33, return_sequences=False))\n",
    "        \n",
    "        model.add(Dense(units=22, activation='relu'))\n",
    "\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss=self._huber_loss,\n",
    "                      optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def update_target_model(self):\n",
    "        # copy weights from model to target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "    def memorize(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        self.sample_memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def train_from_iterations(self):\n",
    "        while True:\n",
    "            samples = []\n",
    "            for _ in range(self.batch_size_samples):\n",
    "                if len(self.sample_memory) != 0:\n",
    "                    samples.append(self.sample_memory.popleft())\n",
    "                else:\n",
    "                    break\n",
    "            if len(samples) != 0:\n",
    "                for state, action, reward, next_state, done in samples:\n",
    "                    self.train(state, action, reward, next_state, done)   \n",
    "\n",
    "    def train(self, state, action, reward, next_state, done):\n",
    "        target = self.model.predict(state, steps=1, verbose=0)\n",
    "        if done and reward > 80 * TIMES_FACTOR:\n",
    "            target[0][action] = reward\n",
    "        else:\n",
    "            # a = self.model.predict(next_state)[0]\n",
    "            t = self.target_model.predict(next_state)[0]\n",
    "            target[0][action] = reward + self.gamma * np.amax(t)\n",
    "            # target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "        self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        # print('done')\n",
    "\n",
    "    def act(self, state):\n",
    "        if not isinstance(state, np.ndarray):\n",
    "            return 0\n",
    "\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size), True\n",
    "        act_values = self.model.predict(state, steps=1)\n",
    "        return np.argmax(act_values[0]), False  # returns action\n",
    "\n",
    "    def predict(self, state):\n",
    "        act_values = self.model.predict(state, steps=1)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self):\n",
    "        while True:\n",
    "            minibatch = random.sample(self.memory, self.batch_size)\n",
    "            for state, action, reward, next_state, done in minibatch:\n",
    "                if not isinstance(state, np.ndarray):\n",
    "                    continue\n",
    "\n",
    "                target = self.model.predict(state, steps=1, verbose=0)\n",
    "                if done and reward > 80 * TIMES_FACTOR:\n",
    "                    target[0][action] = reward\n",
    "                else:\n",
    "                    # a = self.model.predict(next_state)[0]\n",
    "                    t = self.target_model.predict(next_state)[0]\n",
    "                    target[0][action] = reward + self.gamma * np.amax(t)\n",
    "                    # target[0][action] = reward + self.gamma * t[np.argmax(a)]\n",
    "                self.model.fit(state, target, epochs=1, verbose=0)\n",
    "\n",
    "            if self.epsilon > self.epsilon_min:\n",
    "                self.epsilon *= self.epsilon_decay\n",
    "            else:\n",
    "                self.epsilon = self.epsilon_min\n",
    "            \n",
    "            if self.learning_rate > self.learning_rate_min:\n",
    "                self.learning_rate *= self.learning_rate_decay\n",
    "            else:\n",
    "                self.learning_rate = self.learning_rate_min\n",
    "            # print('done')\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "        self.model._make_predict_function()\n",
    "        self.model._make_test_function()\n",
    "        self.model._make_train_function()\n",
    "\n",
    "        self.target_model.load_weights(name)\n",
    "        self.target_model._make_predict_function()\n",
    "        self.target_model._make_test_function()\n",
    "        self.target_model._make_train_function()\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trevor:\n",
    "    POSITIVE_TIMES_REWARD = 0.00001\n",
    "    NEGATIVE_TIMES_REWARD = 0.00001\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "        self.cursor = 0\n",
    "        self.enter_price = 0\n",
    "        self.local_max_price = 0\n",
    "\n",
    "        self.last_action = 0\n",
    "\n",
    "        self.closed_counter = 0\n",
    "        self.total_reward = 0\n",
    "        self.trade_counter = 0\n",
    "\n",
    "        self.closed_counter_list = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.cursor = 0\n",
    "        self.enter_price = 0\n",
    "        self.last_action = 0\n",
    "        self.closed_counter = 0\n",
    "        self.trade_counter = 0\n",
    "        self.total_reward = 0\n",
    "        # self.reset_closed_list()\n",
    "\n",
    "        return self.step(0)[0]\n",
    "\n",
    "    def step(self, action):\n",
    "        sample, last_open, last_close = self.df.get(self.cursor)\n",
    "\n",
    "        reward, closing_trade = self.__process_action(action=action, last_close=last_close)\n",
    "        sample = self.__append_last_action(sample=sample, action=action, last_close=last_close)\n",
    "\n",
    "        self.__increment_cursor()\n",
    "\n",
    "        return sample, reward, closing_trade, ''\n",
    "\n",
    "    def get_total_reward(self):\n",
    "        return self.total_reward\n",
    "\n",
    "    def reset_closed_list(self):\n",
    "        self.closed_counter_list = []\n",
    "\n",
    "    def plot(self, title):\n",
    "        x = list(range(1, len(self.closed_counter_list) + 1))\n",
    "        pyplot.plot(x, self.closed_counter_list)\n",
    "        pyplot.title(str(title))\n",
    "        pyplot.show()\n",
    "\n",
    "    def __process_action(self, action, last_close):\n",
    "        if action < 0 or action > 2:\n",
    "            raise ValueError('Action have to be inrage (0 - 2) got {action}')\n",
    "\n",
    "        closing_trade = False\n",
    "\n",
    "        # \"\"\" CLOSING POSITION \"\"\"\n",
    "        if (self.last_action == 2 and action == 0) or (self.last_action == 1 and action == 0):\n",
    "            reward = self.__close_trade(last_close=last_close)\n",
    "            closing_trade = True\n",
    "\n",
    "        # \"\"\" CLOSING POSITION AND GOING TO DIFFERENT POSITION \"\"\"\n",
    "        elif (self.last_action == 2 and action == 1) or (self.last_action == 1 and action == 2):\n",
    "            reward = self.__close_trade(last_close=last_close) - CLOSING_TRADE_WITH_OPENING\n",
    "            self.enter_price = last_close\n",
    "            self.local_max_price = last_close\n",
    "            closing_trade = True\n",
    "\n",
    "        # \"\"\" HOLDING OPENED POSITION  \"\"\"\n",
    "        elif (self.last_action == 2 and action == 2) or (self.last_action == 1 and action == 1):\n",
    "            if self.last_action == 2:\n",
    "                if self.local_max_price < last_close:\n",
    "                    reward = (last_close - self.enter_price) * REWARD_FOR_PIPS\n",
    "                    self.local_max_price = last_close\n",
    "\n",
    "                else:\n",
    "                    reward = (last_close - self.local_max_price) * REWARD_FOR_PIPS\n",
    "                    reward = reward / DIVIDE_PRICE_UNDER_LOCAL_MINIMA if last_close > self.enter_price \\\n",
    "                        else reward\n",
    "\n",
    "            else:\n",
    "                if self.local_max_price > last_close:\n",
    "                    reward = (self.enter_price - last_close) * REWARD_FOR_PIPS\n",
    "                    self.local_max_price = last_close\n",
    "\n",
    "                else:\n",
    "                    reward = (self.local_max_price - last_close) * REWARD_FOR_PIPS\n",
    "                    reward = reward / DIVIDE_PRICE_UNDER_LOCAL_MINIMA if last_close < self.enter_price \\\n",
    "                        else reward\n",
    "            reward = OPEN_TRADE_REWARD\n",
    "\n",
    "        # \"\"\" OPENING POSITION  \"\"\"\n",
    "        elif (self.last_action == 0 and action == 1) or (self.last_action == 0 and action == 2):\n",
    "            self.enter_price = last_close\n",
    "            self.local_max_price = last_close\n",
    "            # reward = HOLD_REWARD\n",
    "            reward = OPEN_TRADE_REWARD\n",
    "\n",
    "        # \"\"\" HOLD \"\"\"\n",
    "        elif self.last_action == 0 and action == 0:\n",
    "            reward = HOLD_REWARD\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Last action = {self.last_action} and actual_action = {action}')\n",
    "\n",
    "        self.last_action = action\n",
    "        self.total_reward += reward\n",
    "        return reward, closing_trade\n",
    "\n",
    "    def __increment_cursor(self):\n",
    "        \"\"\" Incrementing the cursor, if the cursor is bigger than lenght of the dataframe, then reset it\"\"\"\n",
    "\n",
    "        self.cursor += 1\n",
    "        if self.cursor > self.df.lenght:\n",
    "            self.cursor = 0\n",
    "\n",
    "    def __close_trade(self, last_close):\n",
    "        if self.last_action == 2:\n",
    "            reward = (last_close - self.enter_price) * REWARD_FOR_PIPS * TIMES_FACTOR\n",
    "            self.closed_counter += reward / TIMES_FACTOR\n",
    "            reward += self.POSITIVE_TIMES_REWARD * pow(reward, 3) if reward > 0 \\\n",
    "                else self.NEGATIVE_TIMES_REWARD * pow(reward, 3)\n",
    "\n",
    "        else:\n",
    "            reward = (self.enter_price - last_close) * REWARD_FOR_PIPS * TIMES_FACTOR\n",
    "            self.closed_counter += reward / TIMES_FACTOR\n",
    "            reward += self.POSITIVE_TIMES_REWARD * pow(reward, 3) if reward > 0 \\\n",
    "                else self.NEGATIVE_TIMES_REWARD * pow(reward, 3)\n",
    "\n",
    "        self.closed_counter_list.append(self.closed_counter)\n",
    "        self.trade_counter += 1\n",
    "        return reward\n",
    "\n",
    "    def __append_last_action(self, sample: np.ndarray, action: int, last_close: float):\n",
    "        how_many = sample.shape[1]\n",
    "        decoded_action = ACTION_DECODE[action]\n",
    "\n",
    "        action_arr = (np.expand_dims(np.asarray([decoded_action for i in range(0, how_many)]), axis=1))\n",
    "\n",
    "        if action == 2 or action == 1:\n",
    "            dif = (last_close - self.enter_price)\n",
    "            pip_difference = (np.expand_dims(np.asarray([dif for i in range(0, how_many)]), axis=1))\n",
    "\n",
    "        else:\n",
    "            dif = 0\n",
    "            pip_difference = (np.expand_dims(np.asarray([dif for i in range(0, how_many)]), axis=1))\n",
    "\n",
    "        sample = np.append(sample[0], action_arr, axis=1)\n",
    "        sample = np.append(sample, pip_difference, axis=1)\n",
    "\n",
    "        return np.expand_dims(sample, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-bc003bfa60c0>\", line 5, in <module>\n    agent = DQNAgent(state_size, action_size, batch_size)\n  File \"<ipython-input-4-a83718e9ecf2>\", line 21, in __init__\n    self.model = self._build_model()\n  File \"<ipython-input-4-a83718e9ecf2>\", line 43, in _build_model\n    model.add(CuDNNLSTM(units=200, return_sequences=True, input_shape=self.state_size))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 141, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1316\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1351\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1352\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by {{node cu_dnnlstm_1/CudnnRNN}}with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[{{node cu_dnnlstm_1/CudnnRNN}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bc003bfa60c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maction_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDQNAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# agent.save(\"./save/cartpole-ddqn.h5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a83718e9ecf2>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, state_size, action_size, batch_size)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_target_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \"\"\"Huber loss for Q Learning\n",
      "\u001b[1;32m<ipython-input-4-a83718e9ecf2>\u001b[0m in \u001b[0;36mupdate_target_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate_target_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# copy weights from model to target_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmemorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mget_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(ops)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \"\"\"\n\u001b[0;32m   2419\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m()\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[1;31m# not already marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[1;32m--> 199\u001b[1;33m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n\nCaused by op 'cu_dnnlstm_1/CudnnRNN', defined at:\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n    app.start()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 563, in start\n    self.io_loop.start()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 377, in dispatch_queue\n    yield self.process_one()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 225, in wrapper\n    runner = Runner(result, future, yielded)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 714, in __init__\n    self.run()\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2848, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2874, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3242, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3319, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-bc003bfa60c0>\", line 5, in <module>\n    agent = DQNAgent(state_size, action_size, batch_size)\n  File \"<ipython-input-4-a83718e9ecf2>\", line 21, in __init__\n    self.model = self._build_model()\n  File \"<ipython-input-4-a83718e9ecf2>\", line 43, in _build_model\n    model.add(CuDNNLSTM(units=200, return_sequences=True, input_shape=self.state_size))\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\sequential.py\", line 165, in add\n    layer(x)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\recurrent.py\", line 532, in __call__\n    return super(RNN, self).__call__(inputs, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 457, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 90, in call\n    output, states = self._process_batch(inputs, initial_state)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py\", line 517, in _process_batch\n    is_training=True)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1636, in __call__\n    input_data, input_h, input_c, params, is_training=is_training)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1527, in __call__\n    seed=self._seed)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\contrib\\cudnn_rnn\\python\\ops\\cudnn_rnn_ops.py\", line 1014, in _cudnn_rnn\n    outputs, output_h, output_c, _ = gen_cudnn_rnn_ops.cudnn_rnn(**args)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\", line 141, in cudnn_rnn\n    seed2=seed2, is_training=is_training, name=name)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'CudnnRNN' used by node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) with these attrs: [is_training=true, seed2=0, input_mode=\"linear_input\", T=DT_FLOAT, dropout=0, rnn_mode=\"lstm\", direction=\"unidirectional\", seed=87654321]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[node cu_dnnlstm_1/CudnnRNN (defined at C:\\Users\\hejdu\\Anaconda3\\envs\\gputest\\lib\\site-packages\\keras\\layers\\cudnn_recurrent.py:517) ]]\n"
     ]
    }
   ],
   "source": [
    "env = Trevor(Dataframe())\n",
    "state_size = (NUMBER_OF_SAMPLES, 9)\n",
    "action_size = 3\n",
    "batch_size = 32\n",
    "agent = DQNAgent(state_size, action_size, batch_size)\n",
    "\n",
    "# agent.save(\"./save/cartpole-ddqn.h5\")\n",
    "agent.load(\"./save/cartpole-ddqn.h5\")\n",
    "\n",
    "closed = False\n",
    "run = False\n",
    "\n",
    "for e in range(EPISODES):\n",
    "    state = env.reset()\n",
    "    strt = t_lib.time()\n",
    "    \n",
    "    for time in range(env.df.lenght):\n",
    "        action, random_action = agent.act(state)\n",
    "\n",
    "        if action > 3 or action < 0:\n",
    "            print('Got action ' + action)\n",
    "            continue\n",
    "\n",
    "        next_state, reward, closed, _ = env.step(action)\n",
    "\n",
    "        if not isinstance(next_state, np.ndarray) or not(state, np.ndarray):\n",
    "            print(next_state)\n",
    "            print('NOT NUMPY!!')\n",
    "            continue\n",
    "\n",
    "        # agent.train(state=state, action=action, reward=reward, next_state=next_state, done=closed)\n",
    "        # Thread(target=agent.train, args=[state, action, reward, next_state, closed]).start()\n",
    "        # agent.train(state=state, action=action, reward=reward, next_state=next_state, done=closed)\n",
    "        agent.memorize(state=state, action=action, reward=reward, next_state=next_state, done=closed)\n",
    "        state = next_state\n",
    "        \n",
    "        \"\"\"\n",
    "        print(f'Actual reward = {round(reward, 1)},\\t total reward = {round(env.total_reward, 1)},'\n",
    "              f'\\t action = {action}, \\t trade_counter = {round(env.trade_counter, 1)}, '\n",
    "              f'\\t pip_counter = {round(env.closed_counter, 1)}'\n",
    "              f'\\t random_action = {random_action}'\n",
    "              f'\\t candle_number = {time}')\n",
    "        \"\"\"\n",
    "        # print(\"Actual reward = {}\\t, total reward = {},\\t action = {}\\t trade_counter = {}\\t pip_counter = {}\".format(round(reward, 1), round(env.total_reward, 1), action, round(env.trade_counter, 1), round(env.closed_counter, 1)))\n",
    "        if closed and reward > 80 * TIMES_FACTOR:\n",
    "            agent.update_target_model()\n",
    "            \"\"\"\n",
    "            print(\"episode: {}/{}, score: {}, e: {}, lr: {}\"\n",
    "                  .format(e, EPISODES, time, round(agent.epsilon, 2)), round(agent.learning_rate, 2))\n",
    "            \"\"\"\n",
    "            print(time)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            # agent.replay(batch_size)\n",
    "            if not run:\n",
    "                thr_list = [Thread(target=agent.replay) for _ in range(1)]\n",
    "                for thr in thr_list:\n",
    "                    thr.start()\n",
    "                    t_lib.sleep(1)\n",
    "                    \n",
    "                thr_list = [Thread(target=agent.train_from_iterations) for _ in range(2)]\n",
    "                for thr in thr_list:\n",
    "                    thr.start()\n",
    "                    t_lib.sleep(1)\n",
    "                \n",
    "                run = True\n",
    "                \n",
    "    # clear_output()\n",
    "    env.plot(title='total reward ={};  e = {}, lr={}'.format(round(env.total_reward, 2), round(agent.epsilon, 2), round(agent.learning_rate, 3)))\n",
    "    env.reset_closed_list()\n",
    "    print('Waiting to train the whole dataset')\n",
    "    while not len(agent.sample_memory) == 0:\n",
    "        pass\n",
    "    print('DONE, lets roll!!')\n",
    "    agent.save(\"./save/cartpole-ddqn.h5\")\n",
    "    print(t_lib.time() - strt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
